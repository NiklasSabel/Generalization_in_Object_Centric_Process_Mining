{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3629febf",
   "metadata": {},
   "source": [
    "# Negative Weighted Events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad07bf88",
   "metadata": {},
   "source": [
    "In this notebook, we adapt the negative events-based measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9aeff9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T10:38:42.168582Z",
     "start_time": "2023-04-13T10:38:42.138592Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cd21f2c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from ocpa.objects.log.importer.ocel import factory as ocel_import_factory\n",
    "from ocpa.algo.discovery.ocpn import algorithm as ocpn_discovery_factory\n",
    "from src.utils import get_happy_path_log, create_flower_model, generate_variant_model\n",
    "from ocpa.objects.log.importer.csv import factory as ocel_import_factory_csv\n",
    "#from models.negative_events_measure_without_weighting import negative_events_without_weighting\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b79374dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "#function to filter out the silent transitions defined by a list from a given dictionary\n",
    "def filter_silent_transitions(dic,silent_transitions):\n",
    "    \"\"\"\n",
    "    Function to filter out the silent transitions defined by a list from a given dictionary.\n",
    "    :param dic: dictionary to be filtered, type: dictionary\n",
    "    :param silent_transitions: list of silent transitions in an ocel log, type: list\n",
    "    :return updated_dictionary: filtered dictionary, type: dictionary\n",
    "    \"\"\"\n",
    "    updated_dictionary = {}\n",
    "    for key, values in dic.items():\n",
    "        if key not in silent_transitions:\n",
    "            new_values = [val for val in values if val not in silent_transitions]\n",
    "            updated_dictionary[key] = new_values\n",
    "    return updated_dictionary\n",
    "\n",
    "#recursive implementation of a depth-first search (DFS) algorithm\n",
    "def dfs(graph, visited, activity, preceding_events):\n",
    "    \"\"\"\n",
    "    Function to perform a depth-first search (DFS) algorithm on the activity graph.\n",
    "    :param graph: activity graph, type: dictionary\n",
    "    :param visited: set of already visited nodes, type: set\n",
    "    :param activity: current activity, type: string\n",
    "    :param preceding_events: list to store the preceding events, type: list\n",
    "    \"\"\"\n",
    "    #takes as input the activity graph (represented as a dictionary), a set of visited nodes, the current activity, and a list to store the preceding events.\n",
    "    visited.add(activity)\n",
    "    for preceding_event in graph[activity]:\n",
    "        #eighboring activity has not been visited yet, the algorithm visits it by calling the dfs function with the neighboring activity as the current activity.\n",
    "        if preceding_event not in visited:\n",
    "            dfs(graph, visited, preceding_event, preceding_events)\n",
    "    preceding_events.append(activity)\n",
    "\n",
    "def negative_events_without_weighting(ocel,ocpn):\n",
    "    \"\"\"\n",
    "    Function to calculate the negative events measure without weighting based on the used places inside an object-centric petri-net.\n",
    "    :param ocel: object-centric event log for which the measure should be calculated, type: ocel-log\n",
    "    :param ocpn: corresponding object-centric petri-net, type: object-centric petri-net\n",
    "    :return generalization: final value of the formula, type: float rounded to 4 digits\n",
    "    \"\"\"\n",
    "    #since the process execution mappings have lists of length one,\n",
    "    #we create another dictionary that only contains the the value inside the list to be able to derive the case\n",
    "    mapping_dict = {key: ocel.process_execution_mappings[key][0] for key in ocel.process_execution_mappings}\n",
    "    #we generate a new column in the class (log) that contains the process execution (case) number via the generated dictionary\n",
    "    ocel.log.log['event_execution'] = ocel.log.log.index.map(mapping_dict)\n",
    "    #generate a list of unique events in the event log\n",
    "    events = np.unique(ocel.log.log.event_activity)\n",
    "    # dictionary to store each activity as key and a list of its prior states/places as value\n",
    "    targets = {}\n",
    "    # dictionary to store each activity as key and a list of its following states/places as value\n",
    "    sources = {}\n",
    "    for arc in tqdm(ocpn.arcs, desc=\"Check the arcs\"):\n",
    "        # for each arc, check if our target is a valid transition\n",
    "        if arc.target in ocpn.transitions:\n",
    "            # load all the prior places of a valid transition into a dictionary, where the key is the transition and the value\n",
    "            # a list of all directly prior places\n",
    "            if arc.target.name in targets:\n",
    "                targets[arc.target.name].append(arc.source.name)\n",
    "            else:\n",
    "                targets[arc.target.name] = [arc.source.name]\n",
    "        if arc.source in ocpn.transitions:\n",
    "            # load all the following places of a valid transition into a dictionary, where the key is the transition and the value\n",
    "            # a list of all directly following places\n",
    "            if arc.source.name in sources:\n",
    "                sources[arc.source.name].append(arc.target.name)\n",
    "            else:\n",
    "                sources[arc.source.name] = [arc.target.name]\n",
    "    #generate an empty dictionary to store the directly preceeding transition of an activity\n",
    "    preceding_activities = {}\n",
    "    #use the key and value of targets and source to generate the dictionary\n",
    "    for target_key, target_value in targets.items():\n",
    "        preceding_activities[target_key] = []\n",
    "        for source_key, source_value in sources.items():\n",
    "            for element in target_value:\n",
    "                if element in source_value:\n",
    "                    preceding_activities[target_key].append(source_key)\n",
    "                    break\n",
    "    #generate an empty dictionary to store the directly succeeding transition of an activity\n",
    "    succeeding_activities = {}\n",
    "    for source_key, source_value in sources.items():\n",
    "        succeeding_activities[source_key] = []\n",
    "        for target_key, target_value in targets.items():\n",
    "            for element in source_value:\n",
    "                if element in target_value:\n",
    "                    succeeding_activities[source_key].append(target_key)\n",
    "                    break\n",
    "    #store the name of all silent transitions in the log\n",
    "    silent_transitions = [x.name for x in ocpn.transitions if  x.silent]\n",
    "    #replace the silent transitions in the succeeding activities dictionary by creating a new dictionary to store the modified values\n",
    "    succeeding_activities_updated = {}\n",
    "    # Iterate through the dictionary\n",
    "    for key, values in succeeding_activities.items():\n",
    "        # Create a list to store the modified values for this key\n",
    "        new_values = []\n",
    "        # Iterate through the values of each key\n",
    "        for i in range(len(values)):\n",
    "            # Check if the value is in the list of silent transitions\n",
    "            if values[i] in silent_transitions:\n",
    "                # Replace the value with the corresponding value from the dictionary\n",
    "                new_values.extend(succeeding_activities[values[i]])\n",
    "            else:\n",
    "                # If the value is not in the list of silent transitions, add it to the new list\n",
    "                new_values.append(values[i])\n",
    "        # Add the modified values to the new dictionary\n",
    "        succeeding_activities_updated[key] = new_values\n",
    "    #create an empty dictionary to store all the precedding activities of an activity\n",
    "    preceding_events_dict = {}\n",
    "    # use a depth-first search (DFS) algorithm to traverse the activity graph and\n",
    "    #create a list of all preceding events for each activity in the dictionary for directly preceding activities\n",
    "    for activity in preceding_activities:\n",
    "        #empty set for all the visited activities\n",
    "        visited = set()\n",
    "        #list for all currently preceding events\n",
    "        preceding_events = []\n",
    "        dfs(preceding_activities, visited, activity, preceding_events)\n",
    "        #we need to remove the last element from the list because it corresponds to the activity itself\n",
    "        preceding_events_dict[activity] = preceding_events[:-1][::-1]\n",
    "    #delete all possible silent transitions from preceding_events_dict (dict where all direct preceeding events are stored)\n",
    "    filtered_preceeding_events_full = filter_silent_transitions(preceding_events_dict,silent_transitions)\n",
    "    #delete all possible silent transitions from filtered_preceeding_events (dict where only direct preceeding events are stored)\n",
    "    filtered_preceeding_events = filter_silent_transitions(preceding_activities,silent_transitions)\n",
    "    #delete all possible silent transitions from succeeding_activities_updated (dict where only direct preceeding events are stored)\n",
    "    filtered_succeeding_activities_updated = filter_silent_transitions(succeeding_activities_updated,silent_transitions)\n",
    "    #generate a grouped df such that we can iterate through the log case by case (sort by timestamp to ensure the correct process sequence)\n",
    "    grouped_df = ocel.log.log.sort_values('event_timestamp').groupby('event_execution')\n",
    "    DG = 0 #Disallowed Generalization intialisation\n",
    "    AG = 0 #Allowed Generalization intialisation\n",
    "    # Iterate over each group\n",
    "    for group_name, group_df in tqdm(grouped_df, total=len(grouped_df),desc=\"Calculate Generalization for all process executions\"):\n",
    "        # Iterate over each row in the group\n",
    "        # list for all the activities that are enabled, starting from all activities that do not have any preceeding activity\n",
    "        enabled = [key for key, value in filtered_preceeding_events_full.items() if not value]\n",
    "        # initialise a list of already executed activities in this trace\n",
    "        trace =[]\n",
    "        #iterate through each case/process execution\n",
    "        for index, row in group_df.iterrows():\n",
    "            print(row['event_activity'])\n",
    "            # Get the current negative events based on the current activity to be executed\n",
    "            negative_activities = [x for x in events if x != row['event_activity']]\n",
    "            print(negative_activities)\n",
    "            #it may happen that an activity is not present in the model but nevertheless executed in the log\n",
    "            if row['event_activity'] in enabled:\n",
    "                #check which elements in the negative activity list are enabled outside of the current activity\n",
    "                enabled.remove(row['event_activity'])\n",
    "            #get all the negative events that can not be executed in the process model at the moment\n",
    "            disallowed = [value for value in negative_activities if value not in enabled]\n",
    "            #add activity that has been executed to trace\n",
    "            trace.append(row['event_activity'])\n",
    "            print(trace)\n",
    "            #update the values of allowed and disallowed generalizations based on the paper logic\n",
    "            AG = AG + len(enabled)\n",
    "            DG = DG + len(disallowed)\n",
    "            #may happen that activities in the log are not in the process model\n",
    "            if row['event_activity'] in filtered_succeeding_activities_updated:\n",
    "                #get all possible new enabled activities\n",
    "                possible_enabled = filtered_succeeding_activities_updated[row['event_activity']]\n",
    "                #check if each activity has more than one directly preceeding state\n",
    "                for i in range(len(possible_enabled)):\n",
    "                    #check if an event has two or more activities that need to be executed before the event can take place, if not add events to enabled\n",
    "                    if len(filtered_preceeding_events[possible_enabled[i]]) < 2:\n",
    "                        enabled.append(possible_enabled[i])\n",
    "                    else:\n",
    "                        #if yes, check if all the needed activities have already been performed in this trace\n",
    "                        if all(elem in trace for elem in filtered_preceeding_events[possible_enabled[i]]):\n",
    "                            enabled.append(possible_enabled[i])\n",
    "            #extend the list with all elements that do not have any preceeding activity and are therefore enabled anyways in our process model\n",
    "            enabled.extend([key for key, value in filtered_preceeding_events_full.items() if not value])\n",
    "            #delete all duplicates from the enabled list\n",
    "            enabled = list(set(enabled))\n",
    "        break\n",
    "    #calculate the generalization based on the paper\n",
    "    generalization = AG / (AG+DG)\n",
    "    return np.round(generalization,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaab8829",
   "metadata": {},
   "source": [
    "# P2P Log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7816235",
   "metadata": {},
   "source": [
    "### Standard Petri Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8500148a",
   "metadata": {},
   "source": [
    "In a first step, we load the OCEL-log into the notebook and generate the object-centric petri net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "425aa3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../src/data/jsonocel/p2p-normal.jsonocel\"\n",
    "ocel = ocel_import_factory.apply(filename)\n",
    "ocpn = ocpn_discovery_factory.apply(ocel, parameters={\"debug\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17c6b8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ots = [\"PURCHORD\",\"INVOICE\",\"PURCHREQ\",\"MATERIAL\",\"GDSRCPT\"]\n",
    "ocpn = create_flower_model(filename,ots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c36399e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check the arcs: 100%|██████████| 38/38 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "#since the process execution mappings have lists of length one,\n",
    "#we create another dictionary that only contains the the value inside the list to be able to derive the case\n",
    "mapping_dict = {key: ocel.process_execution_mappings[key][0] for key in ocel.process_execution_mappings}\n",
    "#we generate a new column in the class (log) that contains the process execution (case) number via the generated dictionary\n",
    "ocel.log.log['event_execution'] = ocel.log.log.index.map(mapping_dict)\n",
    "#generate a list of unique events in the event log\n",
    "events = np.unique(ocel.log.log.event_activity)\n",
    "# dictionary to store each activity as key and a list of its prior states/places as value\n",
    "targets = {}\n",
    "# dictionary to store each activity as key and a list of its following states/places as value\n",
    "sources = {}\n",
    "for arc in tqdm(ocpn.arcs, desc=\"Check the arcs\"):\n",
    "    # for each arc, check if our target is a valid transition\n",
    "    if arc.target in ocpn.transitions:\n",
    "        # load all the prior places of a valid transition into a dictionary, where the key is the transition and the value\n",
    "        # a list of all directly prior places\n",
    "        if arc.target.name in targets:\n",
    "            targets[arc.target.name].append(arc.source.name)\n",
    "        else:\n",
    "            targets[arc.target.name] = [arc.source.name]\n",
    "    if arc.source in ocpn.transitions:\n",
    "        # load all the following places of a valid transition into a dictionary, where the key is the transition and the value\n",
    "        # a list of all directly following places\n",
    "        if arc.source.name in sources:\n",
    "            sources[arc.source.name].append(arc.target.name)\n",
    "        else:\n",
    "            sources[arc.source.name] = [arc.target.name]\n",
    "#generate an empty dictionary to store the directly preceeding transition of an activity\n",
    "preceding_activities = {}\n",
    "#use the key and value of targets and source to generate the dictionary\n",
    "for target_key, target_value in targets.items():\n",
    "    preceding_activities[target_key] = []\n",
    "    for source_key, source_value in sources.items():\n",
    "        for element in target_value:\n",
    "            if element in source_value:\n",
    "                preceding_activities[target_key].append(source_key)\n",
    "                break\n",
    "#generate an empty dictionary to store the directly succeeding transition of an activity\n",
    "succeeding_activities = {}\n",
    "for source_key, source_value in sources.items():\n",
    "    succeeding_activities[source_key] = []\n",
    "    for target_key, target_value in targets.items():\n",
    "        for element in source_value:\n",
    "            if element in target_value:\n",
    "                succeeding_activities[source_key].append(target_key)\n",
    "                break\n",
    "#store the name of all silent transitions in the log\n",
    "silent_transitions = [x.name for x in ocpn.transitions if  x.silent]\n",
    "#replace the silent transitions in the succeeding activities dictionary by creating a new dictionary to store the modified values\n",
    "succeeding_activities_updated = {}\n",
    "# Iterate through the dictionary\n",
    "for key, values in succeeding_activities.items():\n",
    "    # Create a list to store the modified values for this key\n",
    "    new_values = []\n",
    "    # Iterate through the values of each key\n",
    "    for i in range(len(values)):\n",
    "        # Check if the value is in the list of silent transitions\n",
    "        if values[i] in silent_transitions:\n",
    "            # Replace the value with the corresponding value from the dictionary\n",
    "            new_values.extend(succeeding_activities[values[i]])\n",
    "        else:\n",
    "            # If the value is not in the list of silent transitions, add it to the new list\n",
    "            new_values.append(values[i])\n",
    "    # Add the modified values to the new dictionary\n",
    "    succeeding_activities_updated[key] = new_values\n",
    "#create an empty dictionary to store all the precedding activities of an activity\n",
    "preceding_events_dict = {}\n",
    "# use a depth-first search (DFS) algorithm to traverse the activity graph and\n",
    "#create a list of all preceding events for each activity in the dictionary for directly preceding activities\n",
    "for activity in preceding_activities:\n",
    "    #empty set for all the visited activities\n",
    "    visited = set()\n",
    "    #list for all currently preceding events\n",
    "    preceding_events = []\n",
    "    dfs(preceding_activities, visited, activity, preceding_events)\n",
    "    #we need to remove the last element from the list because it corresponds to the activity itself\n",
    "    preceding_events_dict[activity] = preceding_events[:-1][::-1]\n",
    "#delete all possible silent transitions from preceding_events_dict (dict where all direct preceeding events are stored)\n",
    "filtered_preceeding_events_full = filter_silent_transitions(preceding_events_dict,silent_transitions)\n",
    "#delete all possible silent transitions from filtered_preceeding_events (dict where only direct preceeding events are stored)\n",
    "filtered_preceeding_events = filter_silent_transitions(preceding_activities,silent_transitions)\n",
    "#delete all possible silent transitions from succeeding_activities_updated (dict where only direct preceeding events are stored)\n",
    "filtered_succeeding_activities_updated = filter_silent_transitions(succeeding_activities_updated,silent_transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e41f30f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Create Purchase Order': ['Goods Issue',\n",
       "  'Plan Goods Issue',\n",
       "  'Receive Goods',\n",
       "  'Verify Material',\n",
       "  'Create Purchase Requisition',\n",
       "  'Issue Goods Receipt',\n",
       "  'Receive Invoice',\n",
       "  'Clear Invoice'],\n",
       " 'Goods Issue': ['Create Purchase Order',\n",
       "  'Plan Goods Issue',\n",
       "  'Receive Goods',\n",
       "  'Verify Material',\n",
       "  'Create Purchase Requisition',\n",
       "  'Issue Goods Receipt',\n",
       "  'Receive Invoice',\n",
       "  'Clear Invoice'],\n",
       " 'Plan Goods Issue': ['Create Purchase Order',\n",
       "  'Goods Issue',\n",
       "  'Receive Goods',\n",
       "  'Verify Material',\n",
       "  'Create Purchase Requisition',\n",
       "  'Issue Goods Receipt',\n",
       "  'Receive Invoice',\n",
       "  'Clear Invoice'],\n",
       " 'Receive Goods': ['Create Purchase Order',\n",
       "  'Goods Issue',\n",
       "  'Plan Goods Issue',\n",
       "  'Verify Material',\n",
       "  'Create Purchase Requisition',\n",
       "  'Issue Goods Receipt',\n",
       "  'Receive Invoice',\n",
       "  'Clear Invoice'],\n",
       " 'Verify Material': ['Create Purchase Order',\n",
       "  'Goods Issue',\n",
       "  'Plan Goods Issue',\n",
       "  'Receive Goods',\n",
       "  'Create Purchase Requisition',\n",
       "  'Issue Goods Receipt',\n",
       "  'Receive Invoice',\n",
       "  'Clear Invoice'],\n",
       " 'Create Purchase Requisition': ['Create Purchase Order',\n",
       "  'Goods Issue',\n",
       "  'Plan Goods Issue',\n",
       "  'Receive Goods',\n",
       "  'Verify Material',\n",
       "  'Issue Goods Receipt',\n",
       "  'Receive Invoice',\n",
       "  'Clear Invoice'],\n",
       " 'Receive Invoice': ['Create Purchase Order',\n",
       "  'Goods Issue',\n",
       "  'Plan Goods Issue',\n",
       "  'Receive Goods',\n",
       "  'Verify Material',\n",
       "  'Create Purchase Requisition',\n",
       "  'Issue Goods Receipt',\n",
       "  'Clear Invoice'],\n",
       " 'Clear Invoice': ['Create Purchase Order',\n",
       "  'Goods Issue',\n",
       "  'Plan Goods Issue',\n",
       "  'Receive Goods',\n",
       "  'Verify Material',\n",
       "  'Create Purchase Requisition',\n",
       "  'Issue Goods Receipt',\n",
       "  'Receive Invoice'],\n",
       " 'Issue Goods Receipt': ['Create Purchase Order',\n",
       "  'Goods Issue',\n",
       "  'Plan Goods Issue',\n",
       "  'Receive Goods',\n",
       "  'Receive Invoice',\n",
       "  'Clear Invoice',\n",
       "  'Verify Material',\n",
       "  'Create Purchase Requisition']}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_preceeding_events_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9be11153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Create Purchase Order': ['Create Purchase Order',\n",
       "  'Goods Issue',\n",
       "  'Plan Goods Issue',\n",
       "  'Receive Goods',\n",
       "  'Verify Material',\n",
       "  'Create Purchase Requisition',\n",
       "  'Receive Invoice',\n",
       "  'Clear Invoice',\n",
       "  'Issue Goods Receipt'],\n",
       " 'Goods Issue': ['Create Purchase Order',\n",
       "  'Goods Issue',\n",
       "  'Plan Goods Issue',\n",
       "  'Receive Goods',\n",
       "  'Verify Material',\n",
       "  'Create Purchase Requisition',\n",
       "  'Issue Goods Receipt'],\n",
       " 'Plan Goods Issue': ['Create Purchase Order',\n",
       "  'Goods Issue',\n",
       "  'Plan Goods Issue',\n",
       "  'Receive Goods',\n",
       "  'Verify Material',\n",
       "  'Create Purchase Requisition',\n",
       "  'Issue Goods Receipt'],\n",
       " 'Receive Goods': ['Create Purchase Order',\n",
       "  'Goods Issue',\n",
       "  'Plan Goods Issue',\n",
       "  'Receive Goods',\n",
       "  'Verify Material',\n",
       "  'Create Purchase Requisition',\n",
       "  'Receive Invoice',\n",
       "  'Clear Invoice',\n",
       "  'Issue Goods Receipt'],\n",
       " 'Verify Material': ['Create Purchase Order',\n",
       "  'Goods Issue',\n",
       "  'Plan Goods Issue',\n",
       "  'Receive Goods',\n",
       "  'Verify Material',\n",
       "  'Create Purchase Requisition',\n",
       "  'Issue Goods Receipt'],\n",
       " 'Create Purchase Requisition': ['Create Purchase Order',\n",
       "  'Goods Issue',\n",
       "  'Plan Goods Issue',\n",
       "  'Receive Goods',\n",
       "  'Verify Material',\n",
       "  'Create Purchase Requisition',\n",
       "  'Issue Goods Receipt'],\n",
       " 'Receive Invoice': ['Create Purchase Order',\n",
       "  'Receive Goods',\n",
       "  'Receive Invoice',\n",
       "  'Clear Invoice',\n",
       "  'Issue Goods Receipt'],\n",
       " 'Clear Invoice': ['Create Purchase Order',\n",
       "  'Receive Goods',\n",
       "  'Receive Invoice',\n",
       "  'Clear Invoice',\n",
       "  'Issue Goods Receipt'],\n",
       " 'Issue Goods Receipt': ['Create Purchase Order',\n",
       "  'Goods Issue',\n",
       "  'Plan Goods Issue',\n",
       "  'Receive Goods',\n",
       "  'Verify Material',\n",
       "  'Create Purchase Requisition',\n",
       "  'Receive Invoice',\n",
       "  'Clear Invoice',\n",
       "  'Issue Goods Receipt']}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_preceeding_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b296bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Create Purchase Order': ['Create Purchase Order',\n",
       "  'Goods Issue',\n",
       "  'Plan Goods Issue',\n",
       "  'Receive Goods',\n",
       "  'Verify Material',\n",
       "  'Create Purchase Requisition',\n",
       "  'Receive Invoice',\n",
       "  'Clear Invoice',\n",
       "  'Issue Goods Receipt'],\n",
       " 'Goods Issue': ['Create Purchase Order',\n",
       "  'Goods Issue',\n",
       "  'Plan Goods Issue',\n",
       "  'Receive Goods',\n",
       "  'Verify Material',\n",
       "  'Create Purchase Requisition',\n",
       "  'Issue Goods Receipt'],\n",
       " 'Plan Goods Issue': ['Create Purchase Order',\n",
       "  'Goods Issue',\n",
       "  'Plan Goods Issue',\n",
       "  'Receive Goods',\n",
       "  'Verify Material',\n",
       "  'Create Purchase Requisition',\n",
       "  'Issue Goods Receipt'],\n",
       " 'Receive Goods': ['Create Purchase Order',\n",
       "  'Goods Issue',\n",
       "  'Plan Goods Issue',\n",
       "  'Receive Goods',\n",
       "  'Verify Material',\n",
       "  'Create Purchase Requisition',\n",
       "  'Receive Invoice',\n",
       "  'Clear Invoice',\n",
       "  'Issue Goods Receipt'],\n",
       " 'Verify Material': ['Create Purchase Order',\n",
       "  'Goods Issue',\n",
       "  'Plan Goods Issue',\n",
       "  'Receive Goods',\n",
       "  'Verify Material',\n",
       "  'Create Purchase Requisition',\n",
       "  'Issue Goods Receipt'],\n",
       " 'Create Purchase Requisition': ['Create Purchase Order',\n",
       "  'Goods Issue',\n",
       "  'Plan Goods Issue',\n",
       "  'Receive Goods',\n",
       "  'Verify Material',\n",
       "  'Create Purchase Requisition',\n",
       "  'Issue Goods Receipt'],\n",
       " 'Receive Invoice': ['Create Purchase Order',\n",
       "  'Receive Goods',\n",
       "  'Receive Invoice',\n",
       "  'Clear Invoice',\n",
       "  'Issue Goods Receipt'],\n",
       " 'Clear Invoice': ['Create Purchase Order',\n",
       "  'Receive Goods',\n",
       "  'Receive Invoice',\n",
       "  'Clear Invoice',\n",
       "  'Issue Goods Receipt'],\n",
       " 'Issue Goods Receipt': ['Create Purchase Order',\n",
       "  'Goods Issue',\n",
       "  'Plan Goods Issue',\n",
       "  'Receive Goods',\n",
       "  'Verify Material',\n",
       "  'Create Purchase Requisition',\n",
       "  'Receive Invoice',\n",
       "  'Clear Invoice',\n",
       "  'Issue Goods Receipt']}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_succeeding_activities_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b611a86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check the arcs: 100%|██████████| 40/40 [00:00<?, ?it/s]\n",
      "Calculate Generalization for all process executions: 100%|██████████| 80/80 [00:00<00:00, 831.46it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1845"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = negative_events_without_weighting (ocel, ocpn)\n",
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a051ca9",
   "metadata": {},
   "source": [
    "### Happy Path Petri Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9910bb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_path__ocel = get_happy_path_log(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "84d3b838",
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_path_ocpn = ocpn_discovery_factory.apply(happy_path__ocel, parameters={\"debug\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aedb409b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check the arcs: 100%|██████████| 38/38 [00:00<?, ?it/s]\n",
      "Calculate Generalization for all process executions: 100%|██████████| 80/80 [00:00<00:00, 788.21it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1958"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = negative_events_without_weighting (ocel, happy_path_ocpn)\n",
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ec2ccf",
   "metadata": {},
   "source": [
    "### Flower Model Petri Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5deafd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "ots = [\"PURCHORD\",\"INVOICE\",\"PURCHREQ\",\"MATERIAL\",\"GDSRCPT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8caa38bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_ocpn = create_flower_model(filename,ots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6b926427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check the arcs: 100%|██████████| 38/38 [00:00<?, ?it/s]\n",
      "Calculate Generalization for all process executions: 100%|██████████| 80/80 [00:00<00:00, 806.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0417"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = negative_events_without_weighting (ocel, flower_ocpn)\n",
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4b6669",
   "metadata": {},
   "source": [
    "### Variant Model Petri Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298076ae",
   "metadata": {},
   "source": [
    "Import the primarly generated variant log for our measure computation, while we generate the variant model with the original log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4544bcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_variant = \"../src/data/csv/p2p_variant_log.csv\" \n",
    "object_types = [\"PURCHORD\",\"INVOICE\",\"PURCHREQ\",\"MATERIAL\",\"GDSRCPT\"]\n",
    "parameters = {\"obj_names\": object_types,\n",
    "              \"val_names\": [],\n",
    "              \"act_name\": \"event_activity\",\n",
    "              \"time_name\": \"event_timestamp\",\n",
    "              \"sep\": \",\"}\n",
    "ocel_variant = ocel_import_factory_csv.apply(file_path=filename_variant, parameters=parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2d3b946c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Variant Models: 100%|██████████| 20/20 [00:02<00:00,  9.39it/s]\n",
      "Processing Variant Nets: 100%|██████████| 20/20 [00:00<00:00, 11168.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########Start generating Object-Centric Petri Net#########\n",
      "#########Finished generating Object-Centric Petri Net#########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "filename = \"../src/data/jsonocel/p2p-normal.jsonocel\"\n",
    "ots = [\"PURCHORD\",\"INVOICE\",\"PURCHREQ\",\"MATERIAL\",\"GDSRCPT\"]\n",
    "ocel = ocel_import_factory.apply(filename)\n",
    "variant_ocpn = generate_variant_model(ocel,save_path_logs='../src/data/csv/p2p_variants/p2p_variant',object_types = ots ,save_path_visuals=f\"../reports/figures/p2p_variant_total.svg\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7ec778a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check the arcs: 100%|██████████| 760/760 [00:00<00:00, 15714.04it/s]\n",
      "Calculate Generalization for all process executions: 100%|██████████| 80/80 [00:00<00:00, 638.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7143"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = negative_events_without_weighting (ocel, variant_ocpn)\n",
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406b591f",
   "metadata": {},
   "source": [
    "# BPI-Challenge 2017 Log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef9fbd0",
   "metadata": {},
   "source": [
    "### Standard Petri Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f37d90",
   "metadata": {},
   "source": [
    "In a first step, we load the OCEL-log into the notebook and generate the object-centric petri net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "97d78201",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../src/data/jsonocel/BPI2017-Final.jsonocel\"\n",
    "ocel = ocel_import_factory.apply(filename)\n",
    "ocpn = ocpn_discovery_factory.apply(ocel, parameters={\"debug\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "24ab8753",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check the arcs: 100%|██████████| 120/120 [00:00<00:00, 72628.64it/s]\n",
      "Calculate Generalization for all process executions: 100%|██████████| 31509/31509 [01:46<00:00, 296.80it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3569"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = negative_events_without_weighting (ocel, ocpn)\n",
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f22ca5",
   "metadata": {},
   "source": [
    "### Happy Path Petri Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "da118f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_path__ocel = get_happy_path_log(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d570317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_path_ocpn = ocpn_discovery_factory.apply(happy_path__ocel, parameters={\"debug\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9582914a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check the arcs: 100%|██████████| 26/26 [00:00<?, ?it/s]\n",
      "Calculate Generalization for all process executions: 100%|██████████| 31509/31509 [01:14<00:00, 423.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1077"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = negative_events_without_weighting (ocel, happy_path_ocpn)\n",
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a62a8d3",
   "metadata": {},
   "source": [
    "### Flower Model Petri Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "69ddb486",
   "metadata": {},
   "outputs": [],
   "source": [
    "ots = [\"application\",\"offer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a60d3fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_ocpn = create_flower_model(filename,ots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ca71b5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check the arcs: 100%|██████████| 56/56 [00:00<00:00, 61166.93it/s]\n",
      "Calculate Generalization for all process executions: 100%|██████████| 31509/31509 [02:01<00:00, 260.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = negative_events_without_weighting (ocel, flower_ocpn)\n",
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a026f0",
   "metadata": {},
   "source": [
    "### Variant Model Petri Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d68a4b",
   "metadata": {},
   "source": [
    "Import the primarly generated variant log for our measure computation, while we generate the variant model with the original log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d553002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_variant = \"../src/data/csv/bpi2017_variant_log.csv\" \n",
    "object_types = [\"application\",\"offer\"]\n",
    "parameters = {\"obj_names\": object_types,\n",
    "              \"val_names\": [],\n",
    "              \"act_name\": \"event_activity\",\n",
    "              \"time_name\": \"event_timestamp\",\n",
    "              \"sep\": \",\"}\n",
    "ocel_variant = ocel_import_factory_csv.apply(file_path=filename_variant, parameters=parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c934c956",
   "metadata": {},
   "source": [
    "We import the pickle file for the variant model of the bpi challenge that we generated in the process models notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5bc14dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ocpa.objects.oc_petri_net.obj.ObjectCentricPetriNet object at 0x000001EDFF0D7850>\n"
     ]
    }
   ],
   "source": [
    "with open(\"../src/data/csv/bpi_variant_ocpn.pickle\", \"rb\") as file:\n",
    "    variant_ocpn = pickle.load(file)\n",
    "\n",
    "print(variant_ocpn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "76eb9de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check the arcs:   0%|          | 935/214724 [00:23<1:28:30, 40.26it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[76], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m value \u001B[38;5;241m=\u001B[39m \u001B[43mnegative_events_without_weighting\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mocel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvariant_ocpn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m value\n",
      "Cell \u001B[1;32mIn[40], line 42\u001B[0m, in \u001B[0;36mnegative_events_without_weighting\u001B[1;34m(ocel, ocpn)\u001B[0m\n\u001B[0;32m     39\u001B[0m sources \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m     40\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m arc \u001B[38;5;129;01min\u001B[39;00m tqdm(ocpn\u001B[38;5;241m.\u001B[39marcs, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCheck the arcs\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m     41\u001B[0m     \u001B[38;5;66;03m# for each arc, check if our target is a valid transition\u001B[39;00m\n\u001B[1;32m---> 42\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43marc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mocpn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransitions\u001B[49m:\n\u001B[0;32m     43\u001B[0m         \u001B[38;5;66;03m# load all the prior places of a valid transition into a dictionary, where the key is the transition and the value\u001B[39;00m\n\u001B[0;32m     44\u001B[0m         \u001B[38;5;66;03m# a list of all directly prior places\u001B[39;00m\n\u001B[0;32m     45\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m arc\u001B[38;5;241m.\u001B[39mtarget\u001B[38;5;241m.\u001B[39mname \u001B[38;5;129;01min\u001B[39;00m targets:\n\u001B[0;32m     46\u001B[0m             targets[arc\u001B[38;5;241m.\u001B[39mtarget\u001B[38;5;241m.\u001B[39mname]\u001B[38;5;241m.\u001B[39mappend(arc\u001B[38;5;241m.\u001B[39msource\u001B[38;5;241m.\u001B[39mname)\n",
      "File \u001B[1;32m~\\PycharmProjects\\Generalization in Object-Centric Process Mining\\venv\\lib\\site-packages\\ocpa\\objects\\oc_petri_net\\obj.py:66\u001B[0m, in \u001B[0;36mObjectCentricPetriNet.Place.__eq__\u001B[1;34m(self, other)\u001B[0m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__eq__\u001B[39m(\u001B[38;5;28mself\u001B[39m, other):\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;66;03m# keep the ID for now in places\u001B[39;00m\n\u001B[1;32m---> 66\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mid\u001B[39;49m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mid\u001B[39m(other)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "value = negative_events_without_weighting (ocel, variant_ocpn)\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504d9663",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
